import requests
from bs4 import BeautifulSoup
import json
import time
import random
from datetime import datetime
import re
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service


class GoldenRabbitCompleteScraper:
    def __init__(self):
        self.books_data = {}
        self.book_count = 0
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Connection': 'keep-alive',
        })
    
    def setup_selenium_driver(self):
        """Selenium WebDriver ì„¤ì •"""
        chrome_options = Options()
        chrome_options.add_argument('--headless')  # ë¸Œë¼ìš°ì € ì°½ ìˆ¨ê¸°ê¸°
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        try:
            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=chrome_options)
            return driver
        except Exception as e:
            print(f"âŒ Chrome WebDriver ì„¤ì • ì‹¤íŒ¨: {e}")
            print("ğŸ“ Chromeì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return None
    
    def load_all_books_with_selenium(self):
        """Seleniumìœ¼ë¡œ ëª¨ë“  ë„ì„œ ë¡œë“œ (Load More ë²„íŠ¼ í´ë¦­)"""
        print("ğŸš€ Seleniumìœ¼ë¡œ ëª¨ë“  ë„ì„œ ë¡œë“œ ì‹œì‘...")
        
        driver = self.setup_selenium_driver()
        if not driver:
            return []
        
        try:
            url = "https://goldenrabbit.co.kr/product-category/books/"
            print(f"ğŸ“š í˜ì´ì§€ ë¡œë“œ: {url}")
            driver.get(url)
            
            # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            time.sleep(3)
            
            # Load More ë²„íŠ¼ì„ ê³„ì† í´ë¦­
            load_more_clicks = 0
            max_clicks = 10  # ìµœëŒ€ 10ë²ˆê¹Œì§€ë§Œ í´ë¦­
            
            while load_more_clicks < max_clicks:
                try:
                    # Load More ë²„íŠ¼ ì°¾ê¸°
                    load_more_selectors = [
                        "a.thb_load_more.button",
                        ".thb_load_more",
                        "a[class*='load_more']",
                        "a[class*='thb_load_more']"
                    ]
                    
                    load_more_button = None
                    for selector in load_more_selectors:
                        try:
                            load_more_button = WebDriverWait(driver, 5).until(
                                EC.element_to_be_clickable((By.CSS_SELECTOR, selector))
                            )
                            break
                        except TimeoutException:
                            continue
                    
                    if not load_more_button:
                        print("ğŸ Load More ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ë„ì„œê°€ ë¡œë“œëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤.")
                        break
                    
                    # ë²„íŠ¼ í…ìŠ¤íŠ¸ í™•ì¸
                    button_text = load_more_button.text.strip()
                    print(f"ğŸ” ë²„íŠ¼ í…ìŠ¤íŠ¸: '{button_text}'")
                    
                    if 'Loading' in button_text or button_text == '':
                        print("â³ ì•„ì§ ë¡œë”© ì¤‘ì´ê±°ë‚˜ ë¹„í™œì„± ìƒíƒœì…ë‹ˆë‹¤. ì ì‹œ ëŒ€ê¸°...")
                        time.sleep(2)
                        continue
                    
                    # ë²„íŠ¼ í´ë¦­ ì „ í˜„ì¬ ë„ì„œ ìˆ˜ ì²´í¬
                    current_books = driver.find_elements(By.CSS_SELECTOR, "ul.products li.product")
                    books_before = len(current_books)
                    print(f"ğŸ“– í´ë¦­ ì „ ë„ì„œ ìˆ˜: {books_before}")
                    
                    # Load More ë²„íŠ¼ í´ë¦­
                    driver.execute_script("arguments[0].click();", load_more_button)
                    load_more_clicks += 1
                    print(f"ğŸ–±ï¸ Load More ë²„íŠ¼ í´ë¦­ #{load_more_clicks}")
                    
                    # ë¡œë”© ëŒ€ê¸°
                    time.sleep(3)
                    
                    # ìƒˆë¡œìš´ ë„ì„œê°€ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
                    current_books = driver.find_elements(By.CSS_SELECTOR, "ul.products li.product")
                    books_after = len(current_books)
                    print(f"ğŸ“– í´ë¦­ í›„ ë„ì„œ ìˆ˜: {books_after}")
                    
                    if books_after <= books_before:
                        print("ğŸ ë” ì´ìƒ ìƒˆë¡œìš´ ë„ì„œê°€ ë¡œë“œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                        break
                    
                    print(f"âœ… {books_after - books_before}ê°œì˜ ìƒˆë¡œìš´ ë„ì„œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    
                except TimeoutException:
                    print("ğŸ Load More ë²„íŠ¼ì´ ë” ì´ìƒ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ë„ì„œê°€ ë¡œë“œëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤.")
                    break
                except Exception as e:
                    print(f"âš ï¸ Load More í´ë¦­ ì¤‘ ì˜¤ë¥˜: {e}")
                    break
            
            # ìµœì¢… ë„ì„œ ë§í¬ë“¤ ìˆ˜ì§‘
            print("\nğŸ“‹ ëª¨ë“  ë„ì„œ ë§í¬ ìˆ˜ì§‘ ì¤‘...")
            
            book_links = []
            book_elements = driver.find_elements(By.CSS_SELECTOR, "ul.products li.product h3 a")
            
            for element in book_elements:
                try:
                    title = element.text.strip()
                    url = element.get_attribute('href')
                    if title and url:
                        book_links.append({
                            'title': title,
                            'url': url
                        })
                except Exception as e:
                    print(f"âš ï¸ ë„ì„œ ë§í¬ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            
            print(f"ğŸ‰ ì´ {len(book_links)}ê°œì˜ ë„ì„œ ë§í¬ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤!")
            return book_links
            
        except Exception as e:
            print(f"âŒ Selenium ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
        finally:
            driver.quit()
    
    def clean_text(self, text):
        """í…ìŠ¤íŠ¸ ì •ë¦¬"""
        if not text:
            return ""
        return re.sub(r'\s+', ' ', text).strip()
    
    def extract_book_detail(self, book_url, book_title):
        """ë„ì„œ ìƒì„¸ í˜ì´ì§€ì—ì„œ ëª¨ë“  ì •ë³´ ì¶”ì¶œ"""
        try:
            print(f"\nğŸ“– ë„ì„œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ: {book_title}")
            print(f"ğŸ”— URL: {book_url}")
            
            # Rate limiting
            time.sleep(random.uniform(2.0, 3.0))
            
            response = self.session.get(book_url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            book_data = {
                'title': book_title,
                'url': book_url,
                'author': '',
                'publisher': 'ê³¨ë“ ë˜ë¹—',
                'publication_date': '',
                'price': '',
                'isbn': '',
                'page_count': '',
                'description': '',
                'table_of_contents': '',
                'publisher_review': '',
                'testimonials': '',
                'cover_image_url': '',
                'category': 'ITì „ë¬¸ì„œ'
            }
            
            # ê°€ê²© ì •ë³´
            price_selectors = [
                '.price .woocommerce-Price-amount.amount',
                '.price .amount',
                'span.price .amount',
                '.woocommerce-Price-amount',
            ]
            
            for selector in price_selectors:
                price_element = soup.select_one(selector)
                if price_element:
                    book_data['price'] = self.clean_text(price_element.get_text())
                    break
            
            # ìƒí’ˆ ì´ë¯¸ì§€
            image_selectors = [
                '.woocommerce-product-gallery__image img',
                '.product-image img',
                '.wp-post-image',
                'img[class*="attachment"]'
            ]
            
            for selector in image_selectors:
                img_element = soup.select_one(selector)
                if img_element:
                    src = img_element.get('src') or img_element.get('data-src')
                    if src:
                        book_data['cover_image_url'] = src
                        break
            
            # ìƒí’ˆ ì •ë³´ í…Œì´ë¸” ë˜ëŠ” ë©”íƒ€ ì •ë³´ì—ì„œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ
            self.extract_product_meta_info(soup, book_data)
            
            # ìƒí’ˆ ì„¤ëª… ì„¹ì…˜ë“¤ ì¶”ì¶œ
            self.extract_product_descriptions(soup, book_data)
            
            # íƒ­ í˜•íƒœì˜ ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
            self.extract_tabbed_content(soup, book_data)
            
            print(f"âœ… ì¶”ì¶œ ì™„ë£Œ:")
            print(f"  - ì €ì: {book_data['author']}")
            print(f"  - ê°€ê²©: {book_data['price']}")
            print(f"  - ì¶œê°„ì¼: {book_data['publication_date']}")
            print(f"  - ISBN: {book_data['isbn']}")
            print(f"  - ì„¤ëª… ê¸¸ì´: {len(book_data['description'])}ì")
            print(f"  - ëª©ì°¨ ê¸¸ì´: {len(book_data['table_of_contents'])}ì")
            print(f"  - ì¶œíŒì‚¬ ë¦¬ë·° ê¸¸ì´: {len(book_data['publisher_review'])}ì")
            print(f"  - ì¶”ì²œí‰ ê¸¸ì´: {len(book_data['testimonials'])}ì")
            
            return book_data
            
        except Exception as e:
            print(f"âŒ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None
    
    def extract_product_meta_info(self, soup, book_data):
        """ìƒí’ˆ ë©”íƒ€ ì •ë³´ ì¶”ì¶œ (ì €ì, ISBN, í˜ì´ì§€ ìˆ˜ ë“±)"""
        # ë‹¤ì–‘í•œ ë©”íƒ€ ì •ë³´ ì„¹ì…˜ ì°¾ê¸°
        meta_selectors = [
            '.product_meta',
            '.woocommerce-product-attributes',
            '.additional-information table',
            '.product-details',
            'table.shop_attributes'
        ]
        
        for meta_selector in meta_selectors:
            meta_section = soup.select_one(meta_selector)
            if meta_section:
                # í…Œì´ë¸” í˜•íƒœ
                rows = meta_section.find_all('tr')
                for row in rows:
                    self.process_meta_row(row, book_data)
                
                # ì •ì˜ ëª©ë¡ í˜•íƒœ (dt, dd)
                dt_elements = meta_section.find_all('dt')
                dd_elements = meta_section.find_all('dd')
                for dt, dd in zip(dt_elements, dd_elements):
                    label = self.clean_text(dt.get_text()).lower()
                    value = self.clean_text(dd.get_text())
                    self.assign_meta_value(label, value, book_data)
                
                # span í˜•íƒœ ë©”íƒ€ ì •ë³´
                spans = meta_section.find_all('span')
                for span in spans:
                    text = self.clean_text(span.get_text())
                    self.parse_meta_text(text, book_data)
    
    def process_meta_row(self, row, book_data):
        """í…Œì´ë¸” í–‰ì—ì„œ ë©”íƒ€ ì •ë³´ ì²˜ë¦¬"""
        th = row.find('th')
        td = row.find('td')
        
        if th and td:
            label = self.clean_text(th.get_text()).lower()
            value = self.clean_text(td.get_text())
            self.assign_meta_value(label, value, book_data)
    
    def assign_meta_value(self, label, value, book_data):
        """ë¼ë²¨ì— ë”°ë¼ ì ì ˆí•œ í•„ë“œì— ê°’ í• ë‹¹"""
        if not value:
            return
        
        if 'ì €ì' in label or 'author' in label:
            book_data['author'] = value
        elif 'isbn' in label:
            book_data['isbn'] = value
        elif 'í˜ì´ì§€' in label or 'page' in label:
            book_data['page_count'] = value
        elif 'ì¶œê°„' in label or 'publish' in label or 'ë°œí–‰' in label:
            book_data['publication_date'] = value
        elif 'í¬ê¸°' in label or 'íŒí˜•' in label or 'size' in label:
            book_data['size'] = value
    
    def parse_meta_text(self, text, book_data):
        """ì¼ë°˜ í…ìŠ¤íŠ¸ì—ì„œ ë©”íƒ€ ì •ë³´ íŒŒì‹±"""
        # "ì €ì : í™ê¸¸ë™" í˜•íƒœ
        if ':' in text:
            parts = text.split(':', 1)
            if len(parts) == 2:
                label = self.clean_text(parts[0]).lower()
                value = self.clean_text(parts[1])
                self.assign_meta_value(label, value, book_data)
    
    def extract_product_descriptions(self, soup, book_data):
        """ìƒí’ˆ ì„¤ëª… ì„¹ì…˜ë“¤ ì¶”ì¶œ"""
        # ì§§ì€ ì„¤ëª…
        short_desc_selectors = [
            '.woocommerce-product-details__short-description',
            '.product-short-description',
            '.entry-summary .product-excerpt'
        ]
        
        for selector in short_desc_selectors:
            element = soup.select_one(selector)
            if element:
                text = self.clean_text(element.get_text())
                if text and len(text) > len(book_data['description']):
                    book_data['description'] = text
                break
    
    def extract_tabbed_content(self, soup, book_data):
        """íƒ­ í˜•íƒœì˜ ì½˜í…ì¸  ì¶”ì¶œ (ì„¤ëª…, ëª©ì°¨, ë¦¬ë·° ë“±)"""
        # WooCommerce íƒ­ êµ¬ì¡°
        tab_selectors = [
            '#tab-description',
            '#tab-reviews',
            '#tab-additional_information',
            '.woocommerce-Tabs-panel--description',
            '.woocommerce-Tabs-panel--additional_information',
            '.woocommerce-Tabs-panel--reviews'
        ]
        
        for selector in tab_selectors:
            tab_content = soup.select_one(selector)
            if tab_content:
                text = self.clean_text(tab_content.get_text())
                
                if 'description' in selector and text:
                    if len(text) > len(book_data['description']):
                        book_data['description'] = text
                elif 'review' in selector and text:
                    book_data['testimonials'] = text
        
        # ì»¤ìŠ¤í…€ íƒ­ë“¤ ì°¾ê¸°
        self.extract_custom_tabs(soup, book_data)
    
    def extract_custom_tabs(self, soup, book_data):
        """ì»¤ìŠ¤í…€ íƒ­ ë˜ëŠ” ì•„ì½”ë””ì–¸ í˜•íƒœì˜ ì½˜í…ì¸  ì¶”ì¶œ"""
        # í•œêµ­ì–´ í‚¤ì›Œë“œë¡œ ì„¹ì…˜ ì°¾ê¸°
        keywords_map = {
            'ëª©ì°¨': 'table_of_contents',
            'ì°¨ë¡€': 'table_of_contents',
            'ì¶œíŒì‚¬': 'publisher_review',
            'ì¶œíŒì‚¬ë¦¬ë·°': 'publisher_review',
            'ì¶œíŒì‚¬ ë¦¬ë·°': 'publisher_review',
            'ì¶”ì²œ': 'testimonials',
            'ì¶”ì²œí‰': 'testimonials',
            'ì„œí‰': 'testimonials',
            'ë¦¬ë·°': 'testimonials',
            'ì±…ì†Œê°œ': 'description',
            'ë‚´ìš©': 'description',
            'ì†Œê°œ': 'description'
        }
        
        # í—¤ë”© íƒœê·¸ë“¤ í™•ì¸
        headings = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
        for heading in headings:
            heading_text = self.clean_text(heading.get_text()).lower()
            
            for keyword, field in keywords_map.items():
                if keyword in heading_text:
                    # í—¤ë”© ë‹¤ìŒì˜ ì½˜í…ì¸  ì°¾ê¸°
                    content = self.get_content_after_heading(heading)
                    if content and len(content) > len(book_data.get(field, '')):
                        book_data[field] = content
                    break
        
        # div í´ë˜ìŠ¤ëª…ìœ¼ë¡œ ì°¾ê¸°
        div_classes = soup.find_all('div', class_=True)
        for div in div_classes:
            class_text = ' '.join(div.get('class', [])).lower()
            
            for keyword, field in keywords_map.items():
                if keyword in class_text:
                    content = self.clean_text(div.get_text())
                    if content and len(content) > len(book_data.get(field, '')):
                        book_data[field] = content
                    break
    
    def get_content_after_heading(self, heading):
        """í—¤ë”© íƒœê·¸ ë‹¤ìŒì˜ ì½˜í…ì¸  ì¶”ì¶œ"""
        content_parts = []
        current = heading.next_sibling
        
        while current and len(content_parts) < 5:  # ìµœëŒ€ 5ê°œ ìš”ì†Œê¹Œì§€
            if hasattr(current, 'get_text'):
                text = self.clean_text(current.get_text())
                if text:
                    content_parts.append(text)
            elif isinstance(current, str):
                text = self.clean_text(current)
                if text:
                    content_parts.append(text)
            
            current = current.next_sibling
            
            # ë‹¤ë¥¸ í—¤ë”©ì„ ë§Œë‚˜ë©´ ì¤‘ë‹¨
            if current and hasattr(current, 'name') and current.name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
                break
        
        return ' '.join(content_parts)
    
    def scrape_all_books(self):
        """ëª¨ë“  ë„ì„œ ì •ë³´ ìŠ¤í¬ë˜í•‘"""
        print("ğŸš€ ê³¨ë“ ë˜ë¹— ì™„ì „ ìŠ¤í¬ë˜í•‘ ì‹œì‘!")
        print("="*60)
        
        # 1. Seleniumìœ¼ë¡œ ëª¨ë“  ë„ì„œ ë§í¬ ìˆ˜ì§‘
        book_links = self.load_all_books_with_selenium()
        
        if not book_links:
            print("âŒ ë„ì„œ ë§í¬ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\nğŸ“š ì´ {len(book_links)}ê°œ ë„ì„œì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤...")
        print("="*60)
        
        # 2. ê° ë„ì„œì˜ ìƒì„¸ ì •ë³´ ì¶”ì¶œ
        for i, book in enumerate(book_links, 1):
            try:
                print(f"\n[{i}/{len(book_links)}] ì§„í–‰ë¥ : {i/len(book_links)*100:.1f}%")
                
                book_data = self.extract_book_detail(book['url'], book['title'])
                
                if book_data:
                    self.book_count += 1
                    self.books_data[f"book_{self.book_count}"] = book_data
                    print(f"âœ… ì„±ê³µ: {book_data['title']}")
                else:
                    print(f"âŒ ì‹¤íŒ¨: {book['title']}")
                    
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ({book['title']}): {e}")
        
        # 3. ê²°ê³¼ ì €ì¥
        self.save_results()
    
    def save_results(self):
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        if not self.books_data:
            print("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"complete_goldenrabbit_books_{timestamp}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.books_data, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ‰ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ!")
            print(f"ğŸ“Š ì´ {len(self.books_data)}ê°œì˜ ë„ì„œ ì •ë³´ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
            print(f"ğŸ’¾ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # í†µê³„ ì¶œë ¥
            self.print_statistics()
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def print_statistics(self):
        """ìˆ˜ì§‘ í†µê³„ ì¶œë ¥"""
        if not self.books_data:
            return
        
        print(f"\nğŸ“ˆ ìˆ˜ì§‘ í†µê³„:")
        
        # ê¸°ë³¸ í†µê³„
        total_books = len(self.books_data)
        books_with_author = sum(1 for book in self.books_data.values() if book.get('author'))
        books_with_price = sum(1 for book in self.books_data.values() if book.get('price'))
        books_with_isbn = sum(1 for book in self.books_data.values() if book.get('isbn'))
        books_with_description = sum(1 for book in self.books_data.values() if book.get('description'))
        books_with_toc = sum(1 for book in self.books_data.values() if book.get('table_of_contents'))
        books_with_review = sum(1 for book in self.books_data.values() if book.get('publisher_review'))
        books_with_testimonials = sum(1 for book in self.books_data.values() if book.get('testimonials'))
        
        print(f"  - ì´ ë„ì„œ ìˆ˜: {total_books}")
        print(f"  - ì €ì ì •ë³´: {books_with_author}/{total_books} ({books_with_author/total_books*100:.1f}%)")
        print(f"  - ê°€ê²© ì •ë³´: {books_with_price}/{total_books} ({books_with_price/total_books*100:.1f}%)")
        print(f"  - ISBN ì •ë³´: {books_with_isbn}/{total_books} ({books_with_isbn/total_books*100:.1f}%)")
        print(f"  - ì±… ì†Œê°œ: {books_with_description}/{total_books} ({books_with_description/total_books*100:.1f}%)")
        print(f"  - ëª©ì°¨: {books_with_toc}/{total_books} ({books_with_toc/total_books*100:.1f}%)")
        print(f"  - ì¶œíŒì‚¬ ë¦¬ë·°: {books_with_review}/{total_books} ({books_with_review/total_books*100:.1f}%)")
        print(f"  - ì¶”ì²œí‰: {books_with_testimonials}/{total_books} ({books_with_testimonials/total_books*100:.1f}%)")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    scraper = GoldenRabbitCompleteScraper()
    scraper.scrape_all_books()


if __name__ == "__main__":
    main()